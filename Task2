import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

# Load the dataset
data = pd.read_csv('customer_purchases.csv')

# Preprocess the data
data = data.dropna()
data = data.drop(columns=['CustomerID'])
scaler = StandardScaler()
scaled_data = scaler.fit_transform(data)

# Determine the optimal number of clusters using the Elbow method
inertia = []
for k in range(1, 11):
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(scaled_data)
    inertia.append(kmeans.inertia_)

plt.plot(range(1, 11), inertia, marker='o')
plt.xlabel('Number of clusters')
plt.ylabel('Inertia')
plt.title('Elbow Method')
plt.show()

# Assume the optimal number of clusters is 3
optimal_clusters = 3

# Apply K-means with the optimal number of clusters
kmeans = KMeans(n_clusters=optimal_clusters, random_state=42)
clusters = kmeans.fit_predict(scaled_data)

# Add cluster labels to the original data
data['Cluster'] = clusters
print(data.head())

# Group by clusters and compute summary statistics
cluster_summary = data.groupby('Cluster').mean()
print(cluster_summary)

# Visualize the clusters
plt.scatter(scaled_data[:, 0], scaled_data[:, 1], c=clusters, cmap='viridis')
plt.xlabel('Purchase Amount (scaled)')
plt.ylabel('Purchase Frequency (scaled)')
plt.title('Customer Segments')
plt.show()
